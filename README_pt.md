<div align="center">
  <img src="https://img.shields.io/badge/Language-ä¸­æ–‡-red.svg" alt="ChinÃªs">
  <img src="https://img.shields.io/badge/Language-English-blue.svg" alt="InglÃªs">
  <img src="https://img.shields.io/badge/Language-EspaÃ±ol-yellow.svg" alt="Espanhol">
  <img src="https://img.shields.io/badge/Language-PortuguÃªs-green.svg" alt="PortuguÃªs">
  <img src="https://img.shields.io/badge/Model-BMSFormer-orange" alt="Modelo">
  <img src="https://img.shields.io/badge/Task-SOH_Estimation-blueviolet" alt="Tarefa">
  
  <h1>ğŸ“š Notas de Leitura: BMSFormer - Um Modelo Eficiente de Estimativa de SOH para BMS com Recursos Limitados</h1>
  <p>Paper: BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator</p>
  
  <div style="margin: 10px 0;">
    <a href="./" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">ç®€ä½“ä¸­æ–‡</a> | 
    <a href="README_en.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">English</a> | 
    <a href="README_es.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">EspaÃ±ol</a> | 
    <a href="#readme" style="padding: 5px 10px; background: #333; border-radius: 4px; text-decoration: none; color: #fff; font-weight: bold;">PortuguÃªs</a>
  </div>
</div>

> **TÃ­tulo do Artigo**: BMSFormer: An efficient deep learning model for online state-of-health estimation...  
> **Revista**: Energy (2024, Vol.313, 134030)  
> **Modelo Principal**: BMSFormer (AtenÃ§Ã£o de FusÃ£o Local-Global + ConvoluÃ§Ã£o SeparÃ¡vel em Profundidade)  
> **Vantagem Chave**: MantÃ©m precisÃ£o de previsÃ£o SOTA enquanto reduz significativamente a complexidade computacional (Complexidade Linear).

## ğŸ” Problemas Centrais
A estimativa atual do estado de saÃºde (SOH) de baterias de Ã­on-lÃ­tio enfrenta um dilema entre "PrecisÃ£o" e "EficiÃªncia":
- **Modelos Leves Tradicionais** (ex: LSTM, SVM): Baixo custo computacional, mas precisÃ£o insuficiente para dados nÃ£o lineares e instÃ¡veis.
- **Modelos Profundos Modernos** (ex: Transformers, CNNs): Alta precisÃ£o, mas dependem de estruturas pesadas, dificultando a implementaÃ§Ã£o em Sistemas de Gerenciamento de Baterias (BMS) com recursos limitados.
- **O Gargalo Softmax**: A autoatenÃ§Ã£o tradicional do Transformer tem complexidade computacional de $O(N^2)$, extremamente lenta para sequÃªncias longas.

## ğŸ’¡ SoluÃ§Ã£o Inovadora: BMSFormer
O artigo propÃµe um modelo de aprendizado profundo leve e de alta eficiÃªncia chamado **BMSFormer**. O fluxo de trabalho inclui: AquisiÃ§Ã£o de dados de segmentos de alta frequÃªncia -> Engenharia de recursos (ExtraÃ§Ã£o de HI) -> Treinamento do modelo -> AvaliaÃ§Ã£o.

> ğŸ“Š **VisÃ£o Geral da Metodologia BMSFormer**
> ![Fluxograma da Metodologia](assets/fig1.jpg)
> *Esta figura ilustra o ciclo completo desde a AquisiÃ§Ã£o de Dados (Etapa 1), Engenharia de Recursos (Etapa 2), Treinamento (Etapa 3), atÃ© a AvaliaÃ§Ã£o (Etapa 4). O nÃºcleo envolve extrair Indicadores de SaÃºde (HIs) altamente correlacionados de segmentos de carga/descarga.*

### MÃ³dulos TÃ©cnicos Principais
1.  **MÃ³dulo LGFA (AtenÃ§Ã£o de FusÃ£o Local-Global)**:
    -   **InovaÃ§Ã£o**: Substitui a AtenÃ§Ã£o Softmax tradicional por AtenÃ§Ã£o Linear baseada em ReLU.
    -   **Efeito**: Reduz a complexidade computacional de $O(N^2)$ para $O(N)$, acelerando significativamente o processamento de sequÃªncias longas.
    -   **FusÃ£o**: Integra o mÃ³dulo DSConv-S para aumentar a sensibilidade a caracterÃ­sticas locais.

> ğŸ“Š **ComparaÃ§Ã£o de Mecanismos de AtenÃ§Ã£o**
> ![ComparaÃ§Ã£o de AtenÃ§Ã£o](assets/fig6.jpg)
> *A comparaÃ§Ã£o mostra (a) AtenÃ§Ã£o Global Softmax Tradicional, (b) AtenÃ§Ã£o Linear, e (c) O mÃ³dulo LGFA proposto. LGFA alcanÃ§a fusÃ£o de complexidade linear de caracterÃ­sticas locais e globais.*

2.  **ConvoluÃ§Ã£o SeparÃ¡vel em Profundidade Multiescala (DSConv)**:
    -   Design de mÃ³dulos **DSConv-S** (nÃºcleo pequeno) e **DSConv-L** (nÃºcleo grande).
    -   Reduz significativamente os parÃ¢metros e FLOPs em comparaÃ§Ã£o com a convoluÃ§Ã£o padrÃ£o.

> ğŸ“Š **Arquitetura do BMSFormer**
> ![Arquitetura do Modelo](assets/fig4.jpg)
> *IlustraÃ§Ã£o detalhada da estrutura BMSFormer, incluindo o mÃ³dulo LGFA, mÃ³dulo DSConv-L e o empilhamento de blocos.*

## ğŸ“ˆ Experimentos e Resultados
O artigo validou o modelo em trÃªs principais conjuntos de dados pÃºblicos: **Oxford**, **NASA** e **CALCE**.

- **Melhoria de PrecisÃ£o**: Comparado com CNN-Transformer, LSTM, etc., o BMSFormer tem o melhor desempenho nas mÃ©tricas RMSE, MAE e MAPE.
- **EficiÃªncia Impressionante**:
    -   Tempo de treinamento reduzido em aproximadamente **21.37%**.
    -   Uso de armazenamento extremamente baixo e estÃ¡vel.

> ğŸ“Š **ComparaÃ§Ã£o de Tamanho de Armazenamento**
> ![ComparaÃ§Ã£o de Armazenamento](assets/fig8.jpg)
> *Esta figura mostra que, sob vÃ¡rias combinaÃ§Ãµes de hiperparÃ¢metros, o BMSFormer (Vermelho) mantÃ©m consistentemente o menor e mais estÃ¡vel tamanho de armazenamento em comparaÃ§Ã£o com outros.*

## ğŸ“š ReferÃªncias
- **CitaÃ§Ã£o**: X. Li, M. Zhao, S. Zhong, et al. BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator[J]. Energy, 2024, 313: 134030.
- **Fontes de Dados**: Oxford Battery Dataset, NASA Prognostics Repository, CALCE Battery Group.
- **PDF do artigo**: <a href="pdf/BMSFormer_Lee2_pure.pdf" style="color: #0078d4; text-decoration: none; font-weight: 500;">ğŸ“„ BMSFormer_Lee2_pure.pdf</a> (Clique para visualizar/baixar)

<br>

<div align="center">
  <p>Â© 2026 Tech Blog Notes | Fonte: <a href="https://doi.org/10.1016/j.energy.2024.134030">Elsevier Energy</a></p>
  <br>
  <a href="./">ç®€ä½“ä¸­æ–‡</a> | 
  <a href="README_en.html">English</a> | 
  <a href="README_es.html">EspaÃ±ol</a> | 
  <a href="#readme">PortuguÃªs</a>
</div>
