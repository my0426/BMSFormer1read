<div align="center">
  <img src="https://img.shields.io/badge/Language-ä¸­æ–‡-red.svg" alt="Chino">
  <img src="https://img.shields.io/badge/Language-English-blue.svg" alt="InglÃ©s">
  <img src="https://img.shields.io/badge/Language-EspaÃ±ol-yellow.svg" alt="EspaÃ±ol">
  <img src="https://img.shields.io/badge/Language-PortuguÃªs-green.svg" alt="PortuguÃ©s">
  <img src="https://img.shields.io/badge/Model-BMSFormer-orange" alt="Modelo">
  <img src="https://img.shields.io/badge/Task-SOH_Estimation-blueviolet" alt="Tarea">
  
  <h1>ðŸ“š Notas de Lectura: BMSFormer - Un modelo eficiente de estimaciÃ³n de SOH para BMS con recursos limitados</h1>
  <p>Paper: BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator</p>
  
  <div style="margin: 10px 0;">
    <a href="./" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">ç®€ä½“ä¸­æ–‡</a> | 
    <a href="README_en.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">English</a> | 
    <a href="#readme" style="padding: 5px 10px; background: #333; border-radius: 4px; text-decoration: none; color: #fff; font-weight: bold;">EspaÃ±ol</a> | 
    <a href="README_pt.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">PortuguÃªs</a>
  </div>
</div>

> [cite_start]**TÃ­tulo del ArtÃ­culo**: BMSFormer: An efficient deep learning model for online state-of-health estimation... [cite: 6]  
> [cite_start]**Revista**: Energy (2024, Vol.313, 134030) [cite: 2]  
> [cite_start]**Modelo Principal**: BMSFormer (AtenciÃ³n de FusiÃ³n Local-Global + ConvoluciÃ³n Separable en Profundidad) [cite: 21, 22]  
> [cite_start]**Ventaja Clave**: Mantiene una precisiÃ³n de predicciÃ³n SOTA mientras reduce significativamente la complejidad computacional (Complejidad Lineal)[cite: 24].

## ðŸ” Problemas Centrales
La estimaciÃ³n actual del estado de salud (SOH) de baterÃ­as de iones de litio enfrenta un dilema entre "PrecisiÃ³n" y "Eficiencia":
- [cite_start]**Modelos Ligeros Tradicionales** (ej. LSTM, SVM): Bajo costo computacional pero precisiÃ³n insuficiente para datos no lineales e inestables[cite: 33].
- [cite_start]**Modelos Profundos Modernos** (ej. Transformers, CNNs): Alta precisiÃ³n pero dependen de estructuras pesadas, lo que dificulta su implementaciÃ³n en Sistemas de GestiÃ³n de BaterÃ­as (BMS) con recursos limitados[cite: 34, 76].
- [cite_start]**El Cuello de Botella Softmax**: La autoatenciÃ³n tradicional de Transformer tiene una complejidad computacional de $O(N^2)$, extremadamente lenta para secuencias largas[cite: 565].

## ðŸ’¡ SoluciÃ³n Innovadora: BMSFormer
El artÃ­culo propone un modelo de aprendizaje profundo ligero y de alta eficiencia llamado **BMSFormer**. El flujo de trabajo incluye: AdquisiciÃ³n de datos de segmentos de alta frecuencia -> IngenierÃ­a de caracterÃ­sticas (ExtracciÃ³n de HI) -> Entrenamiento del modelo -> EvaluaciÃ³n.

> ðŸ“Š **Resumen de la MetodologÃ­a BMSFormer**
> 
> *(Inserte aquÃ­ la **Fig. 1** del artÃ­culo: Flowchart of developed SOH estimation approach)*
> ![Diagrama de Flujo](assets/fig1.jpg)
> *Esta figura ilustra el ciclo completo desde la AdquisiciÃ³n de Datos (Paso 1), IngenierÃ­a de CaracterÃ­sticas (Paso 2), Entrenamiento (Paso 3), hasta la EvaluaciÃ³n (Paso 4). [cite_start]El nÃºcleo implica extraer Indicadores de Salud (HIs) altamente correlacionados de segmentos de carga/descarga.* [cite: 89]

### MÃ³dulos TÃ©cnicos Principales
1.  [cite_start]**MÃ³dulo LGFA (AtenciÃ³n de FusiÃ³n Local-Global)**[cite: 21, 530]:
    -   **InnovaciÃ³n**: Reemplaza la AtenciÃ³n Softmax tradicional con AtenciÃ³n Lineal basada en ReLU.
    -   **Efecto**: Reduce la complejidad computacional de $O(N^2)$ a $O(N)$, acelerando significativamente el procesamiento de secuencias largas.
    -   **FusiÃ³n**: Integra el mÃ³dulo DSConv-S para mejorar la sensibilidad a caracterÃ­sticas locales.

> ðŸ“Š **ComparaciÃ³n de Mecanismos de AtenciÃ³n**
> 
> *(Inserte aquÃ­ la **Fig. 6** del artÃ­culo: Difference between traditional Softmax...)*
> ![ComparaciÃ³n de AtenciÃ³n](assets/fig6.jpg)
> *La comparaciÃ³n muestra (a) AtenciÃ³n Global Softmax Tradicional ($O(N^2)$), (b) AtenciÃ³n Lineal, y (c) El mÃ³dulo LGFA propuesto. [cite_start]LGFA logra una fusiÃ³n de complejidad lineal de caracterÃ­sticas locales y globales.* [cite: 641]

2.  [cite_start]**ConvoluciÃ³n Separable en Profundidad Multiescala (DSConv)**[cite: 22, 428]:
    -   DiseÃ±o de mÃ³dulos **DSConv-S** (nÃºcleo pequeÃ±o) y **DSConv-L** (nÃºcleo grande).
    -   Reduce significativamente los parÃ¡metros y FLOPs comparado con la convoluciÃ³n estÃ¡ndar.

> ðŸ“Š **Arquitectura de BMSFormer**
> 
> *(Inserte aquÃ­ la **Fig. 4** del artÃ­culo: Framework of BMSFormer)*
> ![Arquitectura del Modelo](assets/fig4.jpg)
> [cite_start]*IlustraciÃ³n detallada de la estructura BMSFormer, incluyendo el mÃ³dulo LGFA, mÃ³dulo DSConv-L y el apilamiento de bloques.* [cite: 480]

## ðŸ“ˆ Experimentos y Resultados
[cite_start]El artÃ­culo validÃ³ el modelo en tres conjuntos de datos pÃºblicos principales: **Oxford**, **NASA** y **CALCE**[cite: 23].

- [cite_start]**Mejora de PrecisiÃ³n**: Comparado con CNN-Transformer, LSTM, etc., BMSFormer tiene el mejor rendimiento en mÃ©tricas RMSE, MAE y MAPE[cite: 686].
- **Eficiencia Impresionante**:
    -   [cite_start]Tiempo de entrenamiento reducido aproximadamente un **21.37%**[cite: 905].
    -   Huella de almacenamiento extremadamente baja y estable.

> ðŸ“Š **ComparaciÃ³n de TamaÃ±o de Almacenamiento**
> 
> *(Inserte aquÃ­ la **Fig. 8** del artÃ­culo: Storage size of five models...)*
> ![ComparaciÃ³n de Almacenamiento](assets/fig8.jpg)
> [cite_start]*Esta figura muestra que bajo varias combinaciones de hiperparÃ¡metros, BMSFormer (Rojo) mantiene consistentemente el tamaÃ±o de almacenamiento mÃ¡s bajo y estable en comparaciÃ³n con otros.* [cite: 948]

## ðŸ“š Referencias
- **Cita**: Li, X., Zhao, M., et al. "BMSFormer: An efficient deep learning model for online state-of-health estimation..." Energy 313 (2024): 134030.
- **Fuentes de Datos**: Oxford Battery Dataset, NASA Prognostics Repository, CALCE Battery Group.

<br>

<div align="center">
  <p>Â© 2026 Tech Blog Notes | Fuente: <a href="https://doi.org/10.1016/j.energy.2024.134030">Elsevier Energy</a></p>
  <br>
  <a href="./">ç®€ä½“ä¸­æ–‡</a> | 
  <a href="README_en.html">English</a> | 
  <a href="#readme">EspaÃ±ol</a> | 
  <a href="README_pt.html">PortuguÃªs</a>
</div>
