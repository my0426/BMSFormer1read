<div align="center">
  <img src="https://img.shields.io/badge/Language-ä¸­æ–‡-red.svg" alt="Chino">
  <img src="https://img.shields.io/badge/Language-English-blue.svg" alt="InglÃ©s">
  <img src="https://img.shields.io/badge/Language-EspaÃ±ol-yellow.svg" alt="EspaÃ±ol">
  <img src="https://img.shields.io/badge/Language-PortuguÃªs-green.svg" alt="PortuguÃ©s">
  <img src="https://img.shields.io/badge/Model-BMSFormer-orange" alt="Modelo">
  <img src="https://img.shields.io/badge/Task-SOH_Estimation-blueviolet" alt="Tarea">
  
  <h1>ðŸ“š Notas de Lectura: BMSFormer - Un modelo eficiente de estimaciÃ³n de SOH para BMS con recursos limitados</h1>
  <p>Paper: BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator</p>
  
  <div style="margin: 10px 0;">
    <a href="./" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">ç®€ä½“ä¸­æ–‡</a> | 
    <a href="README_en.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">English</a> | 
    <a href="#readme" style="padding: 5px 10px; background: #333; border-radius: 4px; text-decoration: none; color: #fff; font-weight: bold;">EspaÃ±ol</a> | 
    <a href="README_pt.html" style="padding: 5px 10px; background: #f0f0f0; border-radius: 4px; text-decoration: none; color: #333;">PortuguÃªs</a>
  </div>
</div>

> **TÃ­tulo del ArtÃ­culo**: BMSFormer: An efficient deep learning model for online state-of-health estimation...  
> **Revista**: Energy (2024, Vol.313, 134030)  
> **Modelo Principal**: BMSFormer (AtenciÃ³n de FusiÃ³n Local-Global + ConvoluciÃ³n Separable en Profundidad)  
> **Ventaja Clave**: Mantiene una precisiÃ³n de predicciÃ³n SOTA mientras reduce significativamente la complejidad computacional (Complejidad Lineal).

## ðŸ” Problemas Centrales
La estimaciÃ³n actual del estado de salud (SOH) de baterÃ­as de iones de litio enfrenta un dilema entre "PrecisiÃ³n" y "Eficiencia":
- **Modelos Ligeros Tradicionales** (ej. LSTM, SVM): Bajo costo computacional pero precisiÃ³n insuficiente para datos no lineales e inestables.
- **Modelos Profundos Modernos** (ej. Transformers, CNNs): Alta precisiÃ³n pero dependen de estructuras pesadas, lo que dificulta su implementaciÃ³n en Sistemas de GestiÃ³n de BaterÃ­as (BMS) con recursos limitados.
- **El Cuello de Botella Softmax**: La autoatenciÃ³n tradicional de Transformer tiene una complejidad computacional de $O(N^2)$, extremadamente lenta para secuencias largas.

## ðŸ’¡ SoluciÃ³n Innovadora: BMSFormer
El artÃ­culo propone un modelo de aprendizaje profundo ligero y de alta eficiencia llamado **BMSFormer**. El flujo de trabajo incluye: AdquisiciÃ³n de datos de segmentos de alta frecuencia -> IngenierÃ­a de caracterÃ­sticas (ExtracciÃ³n de HI) -> Entrenamiento del modelo -> EvaluaciÃ³n.

> ðŸ“Š **Resumen de la MetodologÃ­a BMSFormer**
> ![Diagrama de Flujo](assets/fig1.jpg)
> *Esta figura ilustra el ciclo completo desde la AdquisiciÃ³n de Datos (Paso 1), IngenierÃ­a de CaracterÃ­sticas (Paso 2), Entrenamiento (Paso 3), hasta la EvaluaciÃ³n (Paso 4). El nÃºcleo implica extraer Indicadores de Salud (HIs) altamente correlacionados de segmentos de carga/descarga.*

### MÃ³dulos TÃ©cnicos Principales
1.  **MÃ³dulo LGFA (AtenciÃ³n de FusiÃ³n Local-Global)**:
    -   **InnovaciÃ³n**: Reemplaza la AtenciÃ³n Softmax tradicional con AtenciÃ³n Lineal basada en ReLU.
    -   **Efecto**: Reduce la complejidad computacional de $O(N^2)$ a $O(N)$, acelerando significativamente el procesamiento de secuencias largas.
    -   **FusiÃ³n**: Integra el mÃ³dulo DSConv-S para mejorar la sensibilidad a caracterÃ­sticas locales.

> ðŸ“Š **ComparaciÃ³n de Mecanismos de AtenciÃ³n**
> ![ComparaciÃ³n de AtenciÃ³n](assets/fig6.jpg)
> *La comparaciÃ³n muestra (a) AtenciÃ³n Global Softmax Tradicional, (b) AtenciÃ³n Lineal, y (c) El mÃ³dulo LGFA propuesto. LGFA logra una fusiÃ³n de complejidad lineal de caracterÃ­sticas locales y globales.*

2.  **ConvoluciÃ³n Separable en Profundidad Multiescala (DSConv)**:
    -   DiseÃ±o de mÃ³dulos **DSConv-S** (nÃºcleo pequeÃ±o) y **DSConv-L** (nÃºcleo grande).
    -   Reduce significativamente los parÃ¡metros y FLOPs comparado con la convoluciÃ³n estÃ¡ndar.

> ðŸ“Š **Arquitectura de BMSFormer**
> ![Arquitectura del Modelo](assets/fig4.jpg)
> *IlustraciÃ³n detallada de la estructura BMSFormer, incluyendo el mÃ³dulo LGFA, mÃ³dulo DSConv-L y el apilamiento de bloques.*

## ðŸ“ˆ Experimentos y Resultados
El artÃ­culo validÃ³ el modelo en tres conjuntos de datos pÃºblicos principales: **Oxford**, **NASA** y **CALCE**.

- **Mejora de PrecisiÃ³n**: Comparado con CNN-Transformer, LSTM, etc., BMSFormer tiene el mejor rendimiento en mÃ©tricas RMSE, MAE y MAPE.
- **Eficiencia Impresionante**:
    -   Tiempo de entrenamiento reducido aproximadamente un **21.37%**.
    -   Huella de almacenamiento extremadamente baja y estable.

> ðŸ“Š **ComparaciÃ³n de TamaÃ±o de Almacenamiento**
> ![ComparaciÃ³n de Almacenamiento](assets/fig8.jpg)
> *Esta figura muestra que bajo varias combinaciones de hiperparÃ¡metros, BMSFormer (Rojo) mantiene consistentemente el tamaÃ±o de almacenamiento mÃ¡s bajo y estable en comparaciÃ³n con otros.*

## ðŸ“š Referencias
- **Cita**: X. Li, M. Zhao, S. Zhong, et al. BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator[J]. Energy, 2024, 313: 134030.
- **Fuentes de Datos**: Oxford Battery Dataset, NASA Prognostics Repository, CALCE Battery Group.
- **PDF del artÃ­culo**: <a href="pdf/BMSFormer_Lee2_pure.pdf" style="color: #0078d4; text-decoration: none; font-weight: 500;">ðŸ“„ BMSFormer_Lee2_pure.pdf</a> (Haz clic para ver/descargar)

<br>

<div align="center">
  <p>Â© 2026 Tech Blog Notes | Fuente: <a href="https://doi.org/10.1016/j.energy.2024.134030">Elsevier Energy</a></p>
  <br>
  <a href="./">ç®€ä½“ä¸­æ–‡</a> | 
  <a href="README_en.html">English</a> | 
  <a href="#readme">EspaÃ±ol</a> | 
  <a href="README_pt.html">PortuguÃªs</a>
</div>
